{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c66d5d07",
   "metadata": {},
   "source": [
    "# hello_milvus_openai Demo\n",
    "\n",
    "`hello_milvus_openai.ipynb` demonstrates the basic operations of PyMilvus, a Python SDK of Milvus and openAI.\n",
    "Before running, make sure that you have a running Milvus instance.\n",
    "\n",
    "1. connect to Milvus\n",
    "2. create collection\n",
    "3. create embeddings via OpenAI API\n",
    "4. data preparation\n",
    "5. insert data\n",
    "6. create index\n",
    "7. search, query, and hybrid search on entities\n",
    "8. delete entities by PK\n",
    "9. drop collection\n",
    "\n",
    "This notebook is based on original `hello_milvus.ipynb`, and inspired by Pinecone's `gen_qa_openai.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "53299ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from pymilvus import (\n",
    "    connections,\n",
    "    utility,\n",
    "    FieldSchema, CollectionSchema, DataType,\n",
    "    Collection,\n",
    ")\n",
    "\n",
    "search_latency_fmt = \"search latency = {:.4f}s\"\n",
    "dim = 1536\n",
    "auto_id = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5962268",
   "metadata": {},
   "source": [
    "## 1. connect to Milvus\n",
    "\n",
    "Add a new connection alias `default` for Milvus server in `localhost:19530`. \n",
    "\n",
    "Actually the `default` alias is a buildin in PyMilvus. If the address of Milvus is the same as `localhost:19530`, you can omit all parameters and call the method as: `connections.connect()`.\n",
    "\n",
    "Note: the `using` parameter of the following methods is default to \"default\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b0c2d41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does collection hello_milvus exist in Milvus: True\n"
     ]
    }
   ],
   "source": [
    "connections.connect(\"default\", host=\"localhost\", port=\"19530\")\n",
    "\n",
    "has = utility.has_collection(\"hello_milvus_openai\")\n",
    "print(f\"Does collection hello_milvus exist in Milvus: {has}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364f3037",
   "metadata": {},
   "source": [
    "## 2. create collection\n",
    "We're going to create a collection with 3 fields.\n",
    "\n",
    "|   |field name  |field type |other attributes              |  field description      |\n",
    "|---|:----------:|:---------:|:----------------------------:|:-----------------------:|\n",
    "|1  |    \"pk\"    |   INT64/VARCHAR |is_primary=True, auto_id=True/False|      \"primary field\"    |\n",
    "|2  |\"embeddings\"|FloatVector|     dim=8                    |\"float vector with dim 8\"|\n",
    "|3  |   \"text\"   |   VARCHAR |                              |\"varchar\"|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2640964e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if auto_id:\n",
    "    pk_schema = FieldSchema(name=\"pk\", dtype=DataType.INT64, is_primary=True, auto_id=True)\n",
    "else:\n",
    "    pk_schema = FieldSchema(name=\"pk\", dtype=DataType.VARCHAR, is_primary=True, auto_id=False, max_length=100)\n",
    "\n",
    "fields = [\n",
    "    pk_schema,\n",
    "    FieldSchema(name=\"embeddings\", dtype=DataType.FLOAT_VECTOR, dim=dim),\n",
    "    FieldSchema(name=\"text\", dtype=DataType.VARCHAR, max_length=4096)\n",
    "]\n",
    "\n",
    "schema = CollectionSchema(fields, \"hello_milvus_openai is the simplest demo to introduce the APIs\")\n",
    "\n",
    "hello_milvus_openai = Collection(\"hello_milvus_openai\", schema, consistency_level=\"Strong\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b5646f",
   "metadata": {},
   "source": [
    "## 3. create embeddings via OpenAI API\n",
    "We are going to connect to openAI and test connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8cd11437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "# get API key from top-right dropdown on OpenAI website\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\") or \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8f0233b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_model = \"text-embedding-ada-002\"\n",
    "\n",
    "res = openai.Embedding.create(\n",
    "    input=[\n",
    "        \"Sample document text goes here\",\n",
    "        \"there will be several phrases in each batch\"\n",
    "    ], engine=embed_model\n",
    ")\n",
    "len(res['data'][0]['embedding'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58b67e7",
   "metadata": {},
   "source": [
    "We will apply this same embedding logic to a dataset containing information relevant to our query (and many other queries on the topics of ML and AI).\n",
    "\n",
    "## 4. data Preparation\n",
    "\n",
    "The dataset we will be using is the `jamescalam/youtube-transcriptions` from Hugging Face _Datasets_. It contains transcribed audio from several ML and tech YouTube channels. We download it with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c84300c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lazar/miniconda3/envs/autogpt_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Found cached dataset json (/home/lazar/.cache/huggingface/datasets/jamescalam___json/jamescalam--youtube-transcriptions-08d889f6a5386b9b/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['title', 'published', 'url', 'video_id', 'channel_id', 'id', 'text', 'start', 'end'],\n",
       "    num_rows: 208619\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset('jamescalam/youtube-transcriptions', split='train')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "346bbcf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Training and Testing an Italian BERT - Transformers From Scratch #4',\n",
       " 'published': '2021-07-06 13:00:03 UTC',\n",
       " 'url': 'https://youtu.be/35Pdoyi6ZoQ',\n",
       " 'video_id': '35Pdoyi6ZoQ',\n",
       " 'channel_id': 'UCv83tO5cePwHMt1952IVVHw',\n",
       " 'id': '35Pdoyi6ZoQ-t0.0',\n",
       " 'text': 'Hi, welcome to the video.',\n",
       " 'start': 0.0,\n",
       " 'end': 9.36}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638fc034",
   "metadata": {},
   "source": [
    "The dataset contains many small snippets of text data. We will need to merge many snippets from each video to create more substantial chunks of text that contain more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "41966354",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 41724/41724 [00:24<00:00, 1687.12it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "new_data = []\n",
    "\n",
    "window = 10  # number of sentences to combine\n",
    "stride = 5  # number of sentences to 'stride' over, used to create overlap\n",
    "\n",
    "for i in tqdm(range(0, len(data), stride)):\n",
    "    i_end = min(len(data)-1, i+window)\n",
    "    if data[i]['title'] != data[i_end]['title']:\n",
    "        # in this case we skip this entry as we have start/end of two videos\n",
    "        continue\n",
    "    text = ' '.join(data[i:i_end]['text'])\n",
    "    # create the new merged dataset\n",
    "    new_data.append({\n",
    "        'start': data[i]['start'],\n",
    "        'end': data[i_end]['end'],\n",
    "        'title': data[i]['title'],\n",
    "        'text': text,\n",
    "        'id': data[i]['id'],\n",
    "        'url': data[i]['url'],\n",
    "        'published': data[i]['published'],\n",
    "        'channel_id': data[i]['channel_id']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c6d79a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3893"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max((len(d['text']) for d in new_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3a89c9a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start': 0.0,\n",
       " 'end': 39.56,\n",
       " 'title': 'Training and Testing an Italian BERT - Transformers From Scratch #4',\n",
       " 'text': \"Hi, welcome to the video. So this is the fourth video in a Transformers from Scratch mini series. So if you haven't been following along, we've essentially covered what you can see on the screen. So we got some data. We built a tokenizer with it. And then we've set up our input pipeline ready to begin actually training our model, which is what we're going to cover in this video.\",\n",
       " 'id': '35Pdoyi6ZoQ-t0.0',\n",
       " 'url': 'https://youtu.be/35Pdoyi6ZoQ',\n",
       " 'published': '2021-07-06 13:00:03 UTC',\n",
       " 'channel_id': 'UCv83tO5cePwHMt1952IVVHw'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c506bf96",
   "metadata": {},
   "source": [
    "Now we need a place to store these embeddings and enable a efficient _vector search_ through them all. To do that we use milvus collection we created eariler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96587838",
   "metadata": {},
   "source": [
    "## 5. insert data\n",
    "\n",
    "We are going to insert first 10% rows of new_data into `hello_milvus_openai` (for faster execution). Data to be inserted must be organized in fields.\n",
    "\n",
    "The insert() method returns:\n",
    "- either automatically generated primary keys by Milvus if auto_id=True in the schema;\n",
    "- or the existing primary key field from the entities if auto_id=False in the schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4c745947",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 404/404 [09:06<00:00,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entities in Milvus: 37945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from time import sleep\n",
    "\n",
    "batch_size = 100  # how many embeddings we create and insert at once\n",
    "\n",
    "# for i in tqdm(range(0, len(new_data), batch_size)):\n",
    "for i in tqdm(range(0, len(new_data)//10, batch_size)):\n",
    "    # find end of batch\n",
    "    i_end = min(len(new_data), i+batch_size)\n",
    "    meta_batch = new_data[i:i_end]\n",
    "    # get ids\n",
    "    ids_batch = [x['id'] for x in meta_batch]\n",
    "    # get texts to encode\n",
    "    texts = [x['text'] for x in meta_batch]\n",
    "    # create embeddings (try-except added to avoid RateLimitError)\n",
    "    try:\n",
    "        res = openai.Embedding.create(input=texts, engine=embed_model)\n",
    "    except:\n",
    "        done = False\n",
    "        while not done:\n",
    "            sleep(5)\n",
    "            try:\n",
    "                res = openai.Embedding.create(input=texts, engine=embed_model)\n",
    "                done = True\n",
    "            except:\n",
    "                pass\n",
    "    embeds = [record['embedding'] for record in res['data']]\n",
    "    entities = [ids_batch] if not auto_id else [] \n",
    "    entities += [\n",
    "        embeds,\n",
    "        texts\n",
    "    ]\n",
    "    insert_result = hello_milvus_openai.insert(entities)\n",
    "\n",
    "print(f\"Number of entities in Milvus: {hello_milvus_openai.num_entities}\")  # check the num_entites\n",
    "# print(f\"Primary keys of the inserted entities: {insert_result.primary_keys[:3]}\") # check the autogenerated primary_keys\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a56b0d4",
   "metadata": {},
   "source": [
    "## 6. create index\n",
    "We are going to create an IVF_FLAT index for hello_milvus_openai collection.\n",
    "\n",
    "create_index() can only be applied to `FloatVector` and `BinaryVector` fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6d10863e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Status(code=0, message=)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = {\n",
    "    \"index_type\": \"IVF_FLAT\",\n",
    "    \"metric_type\": \"L2\",\n",
    "    \"params\": {\"nlist\": 128},\n",
    "}\n",
    "\n",
    "hello_milvus_openai.create_index(\"embeddings\", index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186765e9",
   "metadata": {},
   "source": [
    "## 7. search, query, and hybrid search\n",
    "After data were inserted into Milvus and indexed, you can perform:\n",
    "- search based on vector similarity\n",
    "- query based on scalar filtering(boolean, int, etc.)\n",
    "- hybrid search based on vector similarity and scalar filtering.\n",
    "\n",
    "Before conducting a search or a query, you need to load the data in `hello_milvus_openai` into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d5a0c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hello_milvus_openai.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ae389a",
   "metadata": {},
   "source": [
    "**Text embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "23bb6ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"We have our data loader. What is the name of that data loader? I'm not sure. Data loader. Cool.\",\n",
       " \"There is an ugly data loader. It's name is unknown :)\"]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_text = \"There is an ugly data loader. It's name is unknown :)\"\n",
    "original_text = new_data[100]['text']\n",
    "\n",
    "search_texts = [original_text, new_text]\n",
    "search_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cdeb8bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = openai.Embedding.create(input=search_texts, engine=embed_model)\n",
    "search_embeds = [record['embedding'] for record in res['data']]\n",
    "len(search_embeds[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0032968a",
   "metadata": {},
   "source": [
    "**Search based on vector similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b7bfeb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "hit: id: 440952106819840763, distance: 0.0, entity: {'text': \"We have our data loader. What is the name of that data loader? I'm not sure. Data loader. Cool.\"}, text field: We have our data loader. What is the name of that data loader? I'm not sure. Data loader. Cool.\n",
      "hit: id: 440952106819840746, distance: 0.19315238296985626, entity: {'text': \"And we're going to initialize our loop object using TQDM. So TQDM. We have our data loader. What is the name of that data loader? I'm not sure.\"}, text field: And we're going to initialize our loop object using TQDM. So TQDM. We have our data loader. What is the name of that data loader? I'm not sure.\n",
      "hit: id: 440952106819840764, distance: 0.23596343398094177, entity: {'text': \"I'm not sure. Data loader. Cool. Data loader. And we set leave equals true.\"}, text field: I'm not sure. Data loader. Cool. Data loader. And we set leave equals true.\n",
      "\n",
      "\n",
      "hit: id: 440952106819840763, distance: 0.2407623827457428, entity: {'text': \"We have our data loader. What is the name of that data loader? I'm not sure. Data loader. Cool.\"}, text field: We have our data loader. What is the name of that data loader? I'm not sure. Data loader. Cool.\n",
      "hit: id: 440952106819840746, distance: 0.3461586833000183, entity: {'text': \"And we're going to initialize our loop object using TQDM. So TQDM. We have our data loader. What is the name of that data loader? I'm not sure.\"}, text field: And we're going to initialize our loop object using TQDM. So TQDM. We have our data loader. What is the name of that data loader? I'm not sure.\n",
      "hit: id: 440952106819840764, distance: 0.3476720452308655, entity: {'text': \"I'm not sure. Data loader. Cool. Data loader. And we set leave equals true.\"}, text field: I'm not sure. Data loader. Cool. Data loader. And we set leave equals true.\n",
      "search latency = 0.3168s\n"
     ]
    }
   ],
   "source": [
    "# search on the last two entity embeddings\n",
    "search_params = {\n",
    "    \"metric_type\": \"L2\",\n",
    "    \"params\": {\"nprobe\": 10},\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "result = hello_milvus_openai.search(search_embeds, \"embeddings\", search_params, limit=3, output_fields=[\"text\"])\n",
    "end_time = time.time()\n",
    "\n",
    "for hits in result:\n",
    "    print('\\n')\n",
    "    for hit in hits:\n",
    "        print(f\"hit: {hit}, text field: {hit.entity.get('text')}\")\n",
    "print(search_latency_fmt.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29b629a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c581caf",
   "metadata": {},
   "source": [
    "## 9. drop collection\n",
    "Finally, drop the hello_milvus collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "341443cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "utility.drop_collection(\"hello_milvus_openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408e22f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
